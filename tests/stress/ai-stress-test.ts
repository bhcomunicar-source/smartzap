#!/usr/bin/env tsx
/**
 * AI Chat Stress Test
 *
 * Testa o sistema de chat com IA sob carga para encontrar:
 * - Race conditions
 * - Memory leaks
 * - Timeouts
 * - Erros de concorr√™ncia
 * - Problemas de rate limiting
 *
 * Uso:
 *   npx tsx tests/stress/ai-stress-test.ts
 *   npx tsx tests/stress/ai-stress-test.ts --vus=20 --turns=5
 *   npx tsx tests/stress/ai-stress-test.ts --aggressive
 */

import { generateWebhookPayload, generateUniquePhone, getRandomMessage } from './webhook-payload'

// =============================================================================
// Configuration
// =============================================================================

interface TestConfig {
  targetUrl: string
  vus: number // Virtual users (conversas paralelas)
  turnsPerConversation: number // Mensagens por conversa
  thinkTime: number // ms entre mensagens do mesmo usu√°rio
  requestTimeout: number // ms
}

function parseArgs(): TestConfig {
  const args = process.argv.slice(2)

  // Profiles
  const isAggressive = args.includes('--aggressive')
  const isQuick = args.includes('--quick')

  // Custom values
  const vusArg = args.find(a => a.startsWith('--vus='))
  const turnsArg = args.find(a => a.startsWith('--turns='))
  const targetArg = args.find(a => a.startsWith('--target='))

  let config: TestConfig = {
    targetUrl: targetArg?.split('=')[1] || 'http://localhost:3001/api/webhook',
    vus: 10,
    turnsPerConversation: 4,
    thinkTime: 500,
    requestTimeout: 60000,
  }

  if (isQuick) {
    config = { ...config, vus: 5, turnsPerConversation: 2 }
  } else if (isAggressive) {
    config = { ...config, vus: 50, turnsPerConversation: 5, thinkTime: 200 }
  }

  // Override with custom args
  if (vusArg) config.vus = parseInt(vusArg.split('=')[1])
  if (turnsArg) config.turnsPerConversation = parseInt(turnsArg.split('=')[1])

  return config
}

// =============================================================================
// Metrics
// =============================================================================

interface RequestResult {
  phone: string
  turn: number
  success: boolean
  status: number
  latencyMs: number
  error?: string
  errorCode?: string
}

const results: RequestResult[] = []
let startTime: number

// =============================================================================
// Test Messages (simulam conversa real)
// =============================================================================

const CONVERSATION_FLOWS = [
  ['Oi, tudo bem?', 'Quero saber sobre os planos', 'Qual o pre√ßo?', 'Tem desconto?', 'Vou pensar'],
  ['Ol√°!', 'Como funciona o WhatsApp marketing?', 'Voc√™s fazem a integra√ß√£o?', 'Preciso de ajuda'],
  ['Boa tarde', 'Tenho uma d√∫vida t√©cnica', 'O sistema est√° fora do ar?', 'Preciso falar com suporte'],
  ['Ei', 'Vi o an√∫ncio de voc√™s', '√â confi√°vel?', 'Quero testar', 'Como come√ßo?'],
  ['Hello', 'Do you speak English?', 'I need help', 'Can you transfer me?'],
  ['Oi', 'Cancelar assinatura', 'N√£o quero mais', 'Tchau'],
  ['Preciso de ajuda urgente', 'Sistema n√£o funciona', 'Isso √© rid√≠culo!', 'Quero meu dinheiro de volta'],
  ['Bom dia!', 'Gostaria de elogiar o atendimento', 'Voc√™s s√£o √≥timos', 'Obrigado!'],
]

function getConversationMessages(conversationIndex: number, turnIndex: number): string {
  const flow = CONVERSATION_FLOWS[conversationIndex % CONVERSATION_FLOWS.length]
  return flow[turnIndex % flow.length] || getRandomMessage()
}

// =============================================================================
// Request Sender
// =============================================================================

async function sendMessage(
  phone: string,
  message: string,
  turn: number,
  config: TestConfig
): Promise<RequestResult> {
  const payload = generateWebhookPayload({ phone, message })
  const requestStart = Date.now()

  try {
    const response = await fetch(config.targetUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Stress-Test': 'true',
        'X-Test-Turn': turn.toString(),
      },
      body: JSON.stringify(payload),
      signal: AbortSignal.timeout(config.requestTimeout),
    })

    const latencyMs = Date.now() - requestStart

    let errorCode: string | undefined
    let errorMessage: string | undefined

    if (!response.ok) {
      try {
        const body = await response.json()
        errorCode = body.error?.code || body.code
        errorMessage = body.error?.message || body.message
      } catch {
        errorCode = `HTTP_${response.status}`
      }
    }

    return {
      phone,
      turn,
      success: response.ok,
      status: response.status,
      latencyMs,
      error: errorMessage,
      errorCode,
    }
  } catch (error) {
    const latencyMs = Date.now() - requestStart

    let errorCode = 'UNKNOWN'
    let errorMessage = 'Unknown error'

    if (error instanceof Error) {
      if (error.name === 'AbortError' || error.name === 'TimeoutError') {
        errorCode = 'TIMEOUT'
        errorMessage = `Request timeout after ${config.requestTimeout}ms`
      } else if (error.message.includes('fetch failed') || error.message.includes('ECONNREFUSED')) {
        errorCode = 'CONNECTION_REFUSED'
        errorMessage = 'Server not reachable'
      } else {
        errorCode = error.name
        errorMessage = error.message
      }
    }

    return {
      phone,
      turn,
      success: false,
      status: 0,
      latencyMs,
      error: errorMessage,
      errorCode,
    }
  }
}

// =============================================================================
// Virtual User (conversa simulada)
// =============================================================================

async function runConversation(
  userId: number,
  config: TestConfig,
  onProgress: (result: RequestResult) => void
): Promise<void> {
  const phone = generateUniquePhone(userId)

  for (let turn = 0; turn < config.turnsPerConversation; turn++) {
    const message = getConversationMessages(userId, turn)
    const result = await sendMessage(phone, message, turn, config)

    results.push(result)
    onProgress(result)

    // Simula tempo de "digita√ß√£o" entre mensagens
    if (turn < config.turnsPerConversation - 1) {
      await new Promise(resolve => setTimeout(resolve, config.thinkTime))
    }
  }
}

// =============================================================================
// Metrics Aggregation
// =============================================================================

interface AggregatedMetrics {
  totalRequests: number
  successfulRequests: number
  failedRequests: number
  successRate: number
  avgLatencyMs: number
  p50LatencyMs: number
  p95LatencyMs: number
  p99LatencyMs: number
  maxLatencyMs: number
  minLatencyMs: number
  errorsByCode: Record<string, number>
  requestsPerSecond: number
  totalDurationMs: number
}

function calculatePercentile(sortedValues: number[], percentile: number): number {
  if (sortedValues.length === 0) return 0
  const index = Math.ceil((percentile / 100) * sortedValues.length) - 1
  return sortedValues[Math.max(0, index)]
}

function aggregateMetrics(): AggregatedMetrics {
  const totalDurationMs = Date.now() - startTime
  const latencies = results.map(r => r.latencyMs).sort((a, b) => a - b)
  const successfulRequests = results.filter(r => r.success).length
  const failedRequests = results.filter(r => !r.success).length

  const errorsByCode: Record<string, number> = {}
  for (const result of results) {
    if (!result.success && result.errorCode) {
      errorsByCode[result.errorCode] = (errorsByCode[result.errorCode] || 0) + 1
    }
  }

  return {
    totalRequests: results.length,
    successfulRequests,
    failedRequests,
    successRate: results.length > 0 ? (successfulRequests / results.length) * 100 : 0,
    avgLatencyMs: latencies.length > 0 ? latencies.reduce((a, b) => a + b, 0) / latencies.length : 0,
    p50LatencyMs: calculatePercentile(latencies, 50),
    p95LatencyMs: calculatePercentile(latencies, 95),
    p99LatencyMs: calculatePercentile(latencies, 99),
    maxLatencyMs: latencies.length > 0 ? Math.max(...latencies) : 0,
    minLatencyMs: latencies.length > 0 ? Math.min(...latencies) : 0,
    errorsByCode,
    requestsPerSecond: results.length / (totalDurationMs / 1000),
    totalDurationMs,
  }
}

// =============================================================================
// Report Generation
// =============================================================================

function generateReport(metrics: AggregatedMetrics, config: TestConfig): string {
  const lines: string[] = []

  lines.push('')
  lines.push('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó')
  lines.push('‚ïë                  AI CHAT STRESS TEST REPORT                      ‚ïë')
  lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
  lines.push(`‚ïë  Target: ${config.targetUrl.padEnd(53)}‚ïë`)
  lines.push(`‚ïë  VUs: ${config.vus.toString().padEnd(56)}‚ïë`)
  lines.push(`‚ïë  Turns/Conversation: ${config.turnsPerConversation.toString().padEnd(41)}‚ïë`)
  lines.push(`‚ïë  Total Requests: ${metrics.totalRequests.toString().padEnd(45)}‚ïë`)
  lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
  lines.push('‚ïë                         RESULTS                                  ‚ïë')
  lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')

  // Success rate com cor
  const successEmoji = metrics.successRate >= 99 ? 'üü¢' : metrics.successRate >= 95 ? 'üü°' : 'üî¥'
  lines.push(`‚ïë  ${successEmoji} Success Rate: ${metrics.successRate.toFixed(2)}%`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  ‚úÖ Successful: ${metrics.successfulRequests}`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  ‚ùå Failed: ${metrics.failedRequests}`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  üìä Requests/sec: ${metrics.requestsPerSecond.toFixed(2)}`.padEnd(65) + '‚ïë')

  lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
  lines.push('‚ïë                        LATENCY                                   ‚ïë')
  lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
  lines.push(`‚ïë  Average: ${metrics.avgLatencyMs.toFixed(0)}ms`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  Min: ${metrics.minLatencyMs.toFixed(0)}ms`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  Max: ${metrics.maxLatencyMs.toFixed(0)}ms`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  P50: ${metrics.p50LatencyMs.toFixed(0)}ms`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  P95: ${metrics.p95LatencyMs.toFixed(0)}ms`.padEnd(65) + '‚ïë')
  lines.push(`‚ïë  P99: ${metrics.p99LatencyMs.toFixed(0)}ms`.padEnd(65) + '‚ïë')

  if (Object.keys(metrics.errorsByCode).length > 0) {
    lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
    lines.push('‚ïë                        ERRORS                                    ‚ïë')
    lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
    for (const [code, count] of Object.entries(metrics.errorsByCode)) {
      lines.push(`‚ïë  ${code}: ${count}`.padEnd(65) + '‚ïë')
    }
  }

  lines.push('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
  lines.push(`‚ïë  Total Duration: ${(metrics.totalDurationMs / 1000).toFixed(1)}s`.padEnd(65) + '‚ïë')
  lines.push('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù')

  return lines.join('\n')
}

// =============================================================================
// Main
// =============================================================================

async function main() {
  const config = parseArgs()

  // Help
  if (process.argv.includes('--help') || process.argv.includes('-h')) {
    console.log(`
AI Chat Stress Test

Uso:
  npx tsx tests/stress/ai-stress-test.ts [op√ß√µes]

Op√ß√µes:
  --target=URL       URL do webhook (default: http://localhost:3001/api/webhook)
  --vus=N            N√∫mero de conversas paralelas (default: 10)
  --turns=N          Mensagens por conversa (default: 4)
  --quick            Teste r√°pido (5 VUs, 2 turns)
  --aggressive       Teste agressivo (50 VUs, 5 turns)
  -h, --help         Mostra esta ajuda

Exemplos:
  # Teste padr√£o
  npx tsx tests/stress/ai-stress-test.ts

  # Teste r√°pido
  npx tsx tests/stress/ai-stress-test.ts --quick

  # Teste customizado
  npx tsx tests/stress/ai-stress-test.ts --vus=30 --turns=6
`)
    process.exit(0)
  }

  console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    AI CHAT STRESS TEST                           ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  Target: ${config.targetUrl.padEnd(53)}‚ïë
‚ïë  Virtual Users: ${config.vus.toString().padEnd(46)}‚ïë
‚ïë  Turns per conversation: ${config.turnsPerConversation.toString().padEnd(37)}‚ïë
‚ïë  Expected requests: ${(config.vus * config.turnsPerConversation).toString().padEnd(42)}‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
`)

  startTime = Date.now()
  let completedRequests = 0
  let successCount = 0
  let failCount = 0

  const onProgress = (result: RequestResult) => {
    completedRequests++
    if (result.success) successCount++
    else failCount++

    const elapsed = ((Date.now() - startTime) / 1000).toFixed(1)
    const rps = (completedRequests / (Date.now() - startTime) * 1000).toFixed(1)

    // Progress line
    process.stdout.write(
      `\r‚è≥ ${elapsed}s | ${completedRequests}/${config.vus * config.turnsPerConversation} reqs | ${rps} req/s | ‚úÖ ${successCount} ‚ùå ${failCount}   `
    )
  }

  console.log('üöÄ Starting conversations...\n')

  // Lan√ßa todas as conversas em paralelo
  const conversations: Promise<void>[] = []
  for (let i = 0; i < config.vus; i++) {
    conversations.push(runConversation(i, config, onProgress))
  }

  // Aguarda todas finalizarem
  await Promise.all(conversations)

  // Clear progress line
  process.stdout.write('\r' + ' '.repeat(80) + '\r')

  // Gera m√©tricas e relat√≥rio
  const metrics = aggregateMetrics()
  const report = generateReport(metrics, config)

  console.log(report)

  // An√°lise de problemas
  console.log('\nüìã AN√ÅLISE DE PROBLEMAS:')

  if (metrics.successRate < 100) {
    console.log(`\n‚ö†Ô∏è  Taxa de sucesso: ${metrics.successRate.toFixed(2)}% (esperado: 100%)`)

    if (metrics.errorsByCode['TIMEOUT']) {
      console.log(`   üïê ${metrics.errorsByCode['TIMEOUT']} timeouts detectados`)
      console.log('      ‚Üí Poss√≠vel gargalo no processamento de IA')
    }

    if (metrics.errorsByCode['CONNECTION_REFUSED']) {
      console.log(`   üîå ${metrics.errorsByCode['CONNECTION_REFUSED']} conex√µes recusadas`)
      console.log('      ‚Üí Servidor pode estar sobrecarregado')
    }

    for (const [code, count] of Object.entries(metrics.errorsByCode)) {
      if (code.startsWith('HTTP_')) {
        console.log(`   üåê ${count}x ${code}`)
      }
    }
  } else {
    console.log('\n‚úÖ Nenhum erro detectado!')
  }

  if (metrics.p95LatencyMs > 10000) {
    console.log(`\n‚ö†Ô∏è  P95 lat√™ncia alta: ${metrics.p95LatencyMs}ms`)
    console.log('   ‚Üí Considere otimizar tempo de resposta da IA')
  }

  if (metrics.maxLatencyMs > 30000) {
    console.log(`\n‚ö†Ô∏è  Lat√™ncia m√°xima muito alta: ${metrics.maxLatencyMs}ms`)
    console.log('   ‚Üí Algumas requisi√ß√µes est√£o demorando muito')
  }

  // Exit code baseado na taxa de sucesso
  if (metrics.successRate < 95) {
    console.log('\n‚ùå TESTE FALHOU: Taxa de sucesso abaixo de 95%')
    process.exit(1)
  }

  console.log('\n‚úÖ TESTE PASSOU!')
}

main().catch(error => {
  console.error('Erro fatal:', error)
  process.exit(1)
})
